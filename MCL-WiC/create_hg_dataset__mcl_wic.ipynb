{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:55:41.582406Z",
     "start_time": "2025-04-24T11:55:41.579939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from config import Credentials\n",
    "from ngram_utils import NgramFetcher\n",
    "from reader import JSONReader"
   ],
   "id": "a2c926a6f0128afa",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T11:40:20.768297Z",
     "start_time": "2025-04-24T11:40:20.741426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "languages = ['ar', 'en', 'fr', 'ru', 'zh']\n",
    "dev_data_path = 'dev/multilingual/dev.{lang}-{lang}.data'\n",
    "dev_gold_path = 'dev/multilingual/dev.{lang}-{lang}.gold'\n",
    "\n",
    "full_data = {}\n",
    "for language in languages:\n",
    "    data = pd.DataFrame(JSONReader().read(dev_data_path.format(lang=language)))\n",
    "    gold = pd.DataFrame(JSONReader().read(dev_gold_path.format(lang=language)))\n",
    "    conc_data = pd.concat([data, gold], axis=1)\n",
    "    data_filtered = conc_data[conc_data['tag'] == 'F'].drop_duplicates(subset=[\"lemma\"])['lemma'].tolist()\n",
    "\n",
    "    full_data[language] = data_filtered"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:43:01.823114Z",
     "start_time": "2025-04-24T11:40:49.357649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "language_map = {\n",
    "    'en', 'fr', 'ru', 'zh'\n",
    "}\n",
    "\n",
    "full_ngram_data = {}\n",
    "for language in languages:\n",
    "    if language in language_map:\n",
    "        full_ngram_data[language] = NgramFetcher().fetch_ngram_data(full_data[language], False, language)"
   ],
   "id": "34f7cd7206710499",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=buzz%2Cpill%2Cspike%2Cthought%2Cfacing%2Cinhibit%2Clandscape%2Cfixing%2Ccheer%2Cban&year_start=1950&year_end=2022&corpus=en&smoothing=3 - sleeping 10 sec.\n",
      "Error fetching Ngram data for batch ['buzz', 'pill', 'spike', 'thought', 'facing', 'inhibit', 'landscape', 'fixing', 'cheer', 'ban']: 429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=buzz%2Cpill%2Cspike%2Cthought%2Cfacing%2Cinhibit%2Clandscape%2Cfixing%2Ccheer%2Cban&year_start=1950&year_end=2022&corpus=en&smoothing=3\n",
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=region%2Ccatch%2Cfriction%2Cfind%2Cfolk%2Cmilk%2Cbraid%2Cempire%2Clap%2Ccoldness&year_start=1950&year_end=2022&corpus=en&smoothing=3 - sleeping 10 sec.\n",
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=actif%2Cbarbu%2Csolide%2Coie%2Chumeur%2Csermon%2Cmouill%C3%A9%2Csommeil%2Cr%C3%A9sident%2Ccomprimer&year_start=1950&year_end=2022&corpus=fr&smoothing=3 - sleeping 10 sec.\n",
      "Error fetching Ngram data for batch ['actif', 'barbu', 'solide', 'oie', 'humeur', 'sermon', 'mouillé', 'sommeil', 'résident', 'comprimer']: 429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=actif%2Cbarbu%2Csolide%2Coie%2Chumeur%2Csermon%2Cmouill%C3%A9%2Csommeil%2Cr%C3%A9sident%2Ccomprimer&year_start=1950&year_end=2022&corpus=fr&smoothing=3\n",
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=ramification%2Cbercer%2Cquartet%2Cv%C5%93u%2Cfurieusement%2Cd%C3%A9pr%C3%A9cier%2Cdard%2Cinflammation%2Ccalme%2Corgie&year_start=1950&year_end=2022&corpus=fr&smoothing=3 - sleeping 10 sec.\n",
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%2C%D1%82%D0%B0%D1%87%D0%BA%D0%B0%2C%D1%80%D0%B0%D0%BA%2C%D0%B7%D0%B2%D0%B5%D0%B7%D0%B4%D0%BD%D1%8B%D0%B9%2C%D0%BF%D0%BB%D0%BE%D1%81%D0%BA%D0%B8%D0%B9%2C%D0%B4%D0%BE%D0%BD%D0%BE%D1%81%D0%B8%D1%82%D1%8C%2C%D0%B3%D0%BE%D1%81%D0%BF%D0%BE%D0%B4%D1%81%D1%82%D0%B2%D0%BE%2C%D1%83%D0%B1%D0%BE%D1%80%D0%BD%D0%B0%D1%8F%2C%D1%83%D0%B4%D0%BE%D0%B1%D1%81%D1%82%D0%B2%D0%BE%2C%D0%BA%D0%B0%D0%B4%D0%B5%D0%BD%D1%86%D0%B8%D1%8F&year_start=1950&year_end=2022&corpus=ru&smoothing=3 - sleeping 10 sec.\n",
      "Error fetching Ngram data for batch ['произведение', 'тачка', 'рак', 'звездный', 'плоский', 'доносить', 'господство', 'уборная', 'удобство', 'каденция']: 429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%2C%D1%82%D0%B0%D1%87%D0%BA%D0%B0%2C%D1%80%D0%B0%D0%BA%2C%D0%B7%D0%B2%D0%B5%D0%B7%D0%B4%D0%BD%D1%8B%D0%B9%2C%D0%BF%D0%BB%D0%BE%D1%81%D0%BA%D0%B8%D0%B9%2C%D0%B4%D0%BE%D0%BD%D0%BE%D1%81%D0%B8%D1%82%D1%8C%2C%D0%B3%D0%BE%D1%81%D0%BF%D0%BE%D0%B4%D1%81%D1%82%D0%B2%D0%BE%2C%D1%83%D0%B1%D0%BE%D1%80%D0%BD%D0%B0%D1%8F%2C%D1%83%D0%B4%D0%BE%D0%B1%D1%81%D1%82%D0%B2%D0%BE%2C%D0%BA%D0%B0%D0%B4%D0%B5%D0%BD%D1%86%D0%B8%D1%8F&year_start=1950&year_end=2022&corpus=ru&smoothing=3\n",
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=%D0%B1%D1%83%D1%82%D1%8B%D0%BB%D0%BE%D1%87%D0%BA%D0%B0%2C%D1%81%D0%BF%D0%BE%D0%BA%D0%BE%D0%B9%D0%BD%D1%8B%D0%B9%2C%D1%83%D1%81%D1%82%D0%B0%D0%BB%D0%BE%D1%81%D1%82%D1%8C%2C%D0%BF%D1%80%D0%B8%D0%BB%D0%B8%D0%B2%2C%D1%81%D0%BA%D0%B0%D0%BA%D0%B0%D1%82%D1%8C%2C%D0%B0%D1%80%D0%BA%D0%B0%D0%B4%D0%B0%2C%D0%B3%D0%BE%D1%80%D0%B8%D0%B7%D0%BE%D0%BD%D1%82%2C%D0%B7%D0%B0%D1%81%D1%82%D1%80%D0%B0%D1%85%D0%BE%D0%B2%D0%B0%D1%82%D1%8C%2C%D0%B2%D1%8B%D1%82%D1%8F%D0%BD%D1%83%D1%82%D1%8C%2C%D0%B8%D1%81%D0%BA%D1%80%D0%B0&year_start=1950&year_end=2022&corpus=ru&smoothing=3 - sleeping 10 sec.\n",
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=%E6%89%8E%2C%E8%AE%A4%E7%9C%9F%E5%9C%B0%2C%E6%A8%A1%E7%89%B9%E5%84%BF%2C%E8%BD%BB%E8%BD%BB%E5%9C%B0%2C%E5%86%B2%E6%B4%97%2C%E4%B8%A5%E8%82%83%E7%9A%84%2C%E8%8C%8E%2C%E7%B4%A7%E6%8F%A1%2C%E9%85%B1%2C%E8%A4%B6%E7%9A%B1&year_start=1950&year_end=2022&corpus=zh&smoothing=3 - sleeping 10 sec.\n",
      "Error fetching Ngram data for batch ['扎', '认真地', '模特儿', '轻轻地', '冲洗', '严肃的', '茎', '紧握', '酱', '褶皱']: 429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=%E6%89%8E%2C%E8%AE%A4%E7%9C%9F%E5%9C%B0%2C%E6%A8%A1%E7%89%B9%E5%84%BF%2C%E8%BD%BB%E8%BD%BB%E5%9C%B0%2C%E5%86%B2%E6%B4%97%2C%E4%B8%A5%E8%82%83%E7%9A%84%2C%E8%8C%8E%2C%E7%B4%A7%E6%8F%A1%2C%E9%85%B1%2C%E8%A4%B6%E7%9A%B1&year_start=1950&year_end=2022&corpus=zh&smoothing=3\n",
      "429 Client Error: Too Many Requests for url: https://books.google.com/ngrams/json?content=%E8%85%90%E8%B4%A5%E7%9A%84%2C%E6%B4%97%E6%8E%89%2C%E8%B6%B3%E8%BF%B9%2C%E8%BD%BB%E4%BE%BF%E7%9A%84%2C%E7%AA%9D%2C%E8%B1%86%2C%E9%95%8C%E5%88%BB%2C%E5%81%B6%E5%83%8F%2C%E7%B2%89%E9%A5%B0%2C%E5%A6%92%E5%BF%8C&year_start=1950&year_end=2022&corpus=zh&smoothing=3 - sleeping 10 sec.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:47:58.290196Z",
     "start_time": "2025-04-24T11:47:58.286497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing = {}\n",
    "for language in languages:\n",
    "    missing[language] = []\n",
    "    for key, value in full_ngram_data.get(language, {}).items():\n",
    "        if 'avg_frequency' not in value:\n",
    "            missing[language].append(key)"
   ],
   "id": "9eda0b71c9a209c5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:49:28.456053Z",
     "start_time": "2025-04-24T11:49:26.850135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ngram_data_missing = {}\n",
    "for language, data in missing.items():\n",
    "    ngram_data_missing[language] = NgramFetcher().fetch_ngram_data(data, False, language)"
   ],
   "id": "d5d6b99f87c1101d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:53:37.179181Z",
     "start_time": "2025-04-24T11:53:37.153381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {}\n",
    "\n",
    "for language in languages:\n",
    "    data[language] = []\n",
    "    lang_data = full_data[language]\n",
    "    for word in lang_data:\n",
    "        if word in full_ngram_data.get(language, {}) or word in ngram_data_missing.get(language, {}):\n",
    "            avg_frequency = full_ngram_data.get(language, {}).get(word, {}).get(\"avg_frequency\") or ngram_data_missing.get(language, {}).get(word, {}).get(\"avg_frequency\")\n",
    "            data[language].append({'word': word, 'avg_google_ngrams_frequency': avg_frequency})\n",
    "        else:\n",
    "            data[language].append({'word': word, 'avg_google_ngrams_frequency': None})"
   ],
   "id": "397dcc5224156912",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:55:46.995764Z",
     "start_time": "2025-04-24T11:55:46.983615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = DatasetDict()\n",
    "for language in languages:\n",
    "    dataset[language] = Dataset.from_list(data[language])"
   ],
   "id": "b7f40482c891b224",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:57:46.897836Z",
     "start_time": "2025-04-24T11:57:46.869089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Features, Value\n",
    "\n",
    "features = Features({\n",
    "    \"word\": Value(\"string\"),\n",
    "    \"avg_google_ngrams_frequency\": Value(\"float64\"),\n",
    "})\n",
    "\n",
    "# Assuming your DatasetDict is called `ds_dict`\n",
    "for lang in dataset:\n",
    "    dataset[lang] = dataset[lang].cast(features)"
   ],
   "id": "b942de3a7f67f28",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 308/308 [00:00<00:00, 81463.34 examples/s]\n",
      "Casting the dataset: 100%|██████████| 334/334 [00:00<00:00, 240126.42 examples/s]\n",
      "Casting the dataset: 100%|██████████| 380/380 [00:00<00:00, 248997.89 examples/s]\n",
      "Casting the dataset: 100%|██████████| 330/330 [00:00<00:00, 316659.88 examples/s]\n",
      "Casting the dataset: 100%|██████████| 254/254 [00:00<00:00, 246838.09 examples/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T11:57:57.788615Z",
     "start_time": "2025-04-24T11:57:50.085796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset.push_to_hub(\n",
    "    repo_id=\"lukasellinger/homonym-mcl-wic\",\n",
    "    private=True,\n",
    "    token=Credentials.hf_api_key\n",
    ")"
   ],
   "id": "f276fee1a9ab6db3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1123.57ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1014.10ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 883.38ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1400.44ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1162.50ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/lukasellinger/homonym-mcl-wic/commit/9f08feea7f4042ad6dddf5af553f9fb2ed0e7d95', commit_message='Upload dataset', commit_description='', oid='9f08feea7f4042ad6dddf5af553f9fb2ed0e7d95', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/lukasellinger/homonym-mcl-wic', endpoint='https://huggingface.co', repo_type='dataset', repo_id='lukasellinger/homonym-mcl-wic'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
